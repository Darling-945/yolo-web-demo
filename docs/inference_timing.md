# 推理时间显示功能说明

## 功能概述

在YOLO目标检测结果页面添加了推理耗时显示功能，让用户可以直观地了解模型推理的性能。

## 显示位置

### 1. Toast通知
- **位置**: 页面加载完成时弹出
- **内容**: "检测完成！推理耗时: X.XXX秒 (模型格式)"
- **用途**: 即时告知用户推理完成及性能信息

### 2. 检测摘要区域
- **位置**: 结果统计卡片中的"推理性能"部分
- **内容**:
  - 推理时间（精确到毫秒）
  - 使用模型（如 YOLO11N）
  - 模型格式（PYTORCH/ONNX/TENSORRT）
- **样式**: 绿色成功提示框，带图标美化

### 3. 检测详情区域
- **位置**: "检测到的目标"表格
- **内容**: 仅显示检测到的目标信息
  - 目标类型
  - 置信度
  - 边界框坐标
- **样式**: 简洁的表格布局，专注于目标信息

## 技术实现

### 后端修改
1. **model_inference.py**
   - 添加了`time`模块导入
   - 在推理前后添加时间戳记录
   - 计算推理耗时并添加到结果中

2. **数据结构更新**
   ```python
   summary = {
       # ... 其他字段
       'inference_time': round(inference_time, 4),  # 推理时间(秒)
       'model_format': self.model_format  # 模型格式
   }
   ```

### 前端修改
1. **inference.html**
   - 添加了Toast通知显示推理完成信息
   - 在检测摘要区域添加性能指标显示
   - 在检测详情区域添加性能指标摘要

## 支持的模型格式

- **PyTorch (.pt)**: 标准YOLO模型格式
- **ONNX (.onnx)**: CPU优化格式
- **TensorRT (.engine)**: GPU加速格式

不同格式的推理时间会有显著差异，用户可以通过此功能比较不同格式的性能。

## 精度说明

- 推理时间精确到毫秒（小数点后3位）
- 仅计算纯模型推理时间，不包括图片加载和后处理
- 时间测量使用Python标准库的`time.time()`函数

## 用户体验

1. **即时反馈**: 页面加载时立即显示推理完成通知
2. **信息分离**: 推理性能信息集中在摘要区域，目标信息集中在详情区域
3. **简洁明了**: 布局清晰，信息展示更有针对性
4. **性能透明**: 用户可以清楚了解模型的推理性能
5. **格式对比**: 有助于用户选择最适合的模型格式
6. **性能优化**: 为模型优化提供数据支持

## 示例输出

```
Toast通知: "检测完成！推理耗时: 0.245秒 (PYTORCH模型)"

摘要区域 - 推理性能:
┌─────────────────┬───────────┬───────────┐
│     推理时间    │   使用模型  │  模型格式 │
├─────────────────┼───────────┼───────────┤
│     0.245s      │   YOLO11N  │  PYTORCH  │
└─────────────────┴───────────┴───────────┘

详情区域 - 检测到的目标:
┌─────────────┬──────────┬─────────────────────────┐
│   目标类型   │  置信度  │      边界框坐标        │
├─────────────┼──────────┼─────────────────────────┤
│    person    │   0.85   │ [100, 100, 200, 200]   │
│     car      │   0.92   │ [50, 300, 250, 400]    │
└─────────────┴──────────┴─────────────────────────┘
```

## 注意事项

1. 推理时间会因设备性能而异
2. 不同图片大小会影响推理时间
3. 模型复杂度是影响推理时间的主要因素
4. 首次加载模型可能需要额外的初始化时间

此功能为用户提供了完整的推理性能透明度，有助于优化模型选择和性能调优。